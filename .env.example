# ============================================================
# Scraper Service Configuration
# ============================================================
# Copy to .env and fill in values.
# In production (Coolify), set these as environment variables.
# ============================================================

# Auth — API key for all protected endpoints
API_KEY=your-secret-api-key

# Database — PostgreSQL connection string
# Dev:  postgresql://scraper:scraper@localhost:5433/scraper_service
# Prod: set via Coolify env vars (internal docker network uses port 5432)
DATABASE_URL=postgresql://scraper:scraper@localhost:5433/scraper_service

# Brave Search API keys
BRAVE_API_KEY=
BRAVE_API_KEY_AI=

# Proxies (comma-separated URLs)
DATACENTER_PROXIES=
RESIDENTIAL_PROXIES=

# Playwright browser pool
PLAYWRIGHT_POOL_SIZE=3

# Cache
PAGE_CACHE_TTL_SECONDS=1800
PAGE_CACHE_MAX_SIZE=1000
DEFAULT_SCRAPE_TTL_DAYS=30

# Concurrency
MAX_SCRAPE_CONCURRENCY=20
MAX_RESEARCH_CONCURRENCY=30

# Server
HOST=0.0.0.0
PORT=8001

# ============================================================
# Backups (S3) — used by scripts/backup.sh
# ============================================================
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=us-east-2
BACKUP_S3_BUCKET=matrix-models
BACKUP_S3_PREFIX=backups/scraper-service

# ============================================================
# Docker Compose overrides
# ============================================================
# POSTGRES_USER=scraper
# POSTGRES_PASSWORD=scraper
# POSTGRES_DB=scraper_service
# POSTGRES_PORT=5433
# APP_PORT=8001
